{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb61jB2+aCvWHRnvWh2eHB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmrNawar/AIE314-Tutorial1/blob/main/Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p55FvK1wIAgU",
        "outputId": "b7c13f27-fd90-437b-db5b-ac340bdacde3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spire.doc in /usr/local/lib/python3.11/dist-packages (13.1.0)\n",
            "Requirement already satisfied: plum-dispatch==1.7.4 in /usr/local/lib/python3.11/dist-packages (from spire.doc) (1.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install spire.doc\n",
        "from spire.doc import *\n",
        "from spire.doc.common import *\n",
        "\n",
        "document = Document()\n",
        "document.LoadFromFile(\"file-sample_100kB.doc\")\n",
        "document_text = document.GetText()\n",
        "with open(\"Output/DocumentText.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(document_text)\n",
        "\n",
        "document.Close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Spire.Presentation\n",
        "from spire.presentation import *\n",
        "from spire.presentation.common import *\n",
        "\n",
        "presentation = Presentation()\n",
        "presentation.LoadFromFile(\"Little Red Riding Hood Storybook by Slidesgo.pptx\")\n",
        "\n",
        "text = []\n",
        "for slide in presentation.Slides:\n",
        "    for shape in slide.Shapes:\n",
        "        if isinstance(shape, IAutoShape) and shape.TextFrame is not None:\n",
        "            for paragraph in shape.TextFrame.Paragraphs:\n",
        "                text.append(paragraph.Text)\n",
        "f = open(\"Output/ExtractAllText.txt\",\"w\", encoding = 'utf-8')\n",
        "for s in text:\n",
        "    f.write(s + \"\\n\")\n",
        "f.close()\n",
        "\n",
        "# Dispose resources\n",
        "presentation.Dispose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSDNSU8cIu1s",
        "outputId": "77acd749-bda7-4a4c-ebcb-569b37c29ea7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Spire.Presentation in /usr/local/lib/python3.11/dist-packages (10.1.0)\n",
            "Requirement already satisfied: plum-dispatch==1.7.4 in /usr/local/lib/python3.11/dist-packages (from Spire.Presentation) (1.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Spire.PDF\n",
        "from spire.pdf.common import *\n",
        "from spire.pdf import *\n",
        "def extract_text_from_pdf(file_path, output_file):\n",
        "    # Load a PDF document\n",
        "    doc = PdfDocument()\n",
        "    # Use the file_path parameter instead of a hardcoded path\n",
        "    doc.LoadFromFile(\"sample.pdf\")\n",
        "\n",
        "    extracted_text = []\n",
        "    for i in range(doc.Pages.Count):\n",
        "        page = doc.Pages.get_Item(i)\n",
        "        # Extract the text from the page\n",
        "        textExtractor = PdfTextExtractor(page)\n",
        "        option = PdfTextExtractOptions()\n",
        "        text = textExtractor.ExtractText(option)\n",
        "        extracted_text.append(text)\n",
        "\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "        text_file.write(\"\\n\".join(extracted_text))\n",
        "\n",
        "    doc.Close()\n",
        "file_path = \"sample-1.pdf\"\n",
        "output_file = \"PDFText.txt\"\n",
        "extract_text_from_pdf(file_path, output_file)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8oIuL1HJtRf",
        "outputId": "8a5eed05-4517-4acc-b7d2-f705419c48c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Spire.PDF in /usr/local/lib/python3.11/dist-packages (10.12.1)\n",
            "Requirement already satisfied: plum-dispatch==1.7.4 in /usr/local/lib/python3.11/dist-packages (from Spire.PDF) (1.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.yallakora.com/egyptian-league/2935/fixtures/%d8%a7%d9%84%d8%af%d9%88%d8%b1%d9%8a-%d8%a7%d9%84%d9%85%d8%b5%d8%b1%d9%8a#tour-matches\"\n",
        "response = requests.get(url)\n",
        "html_content = response.content\n",
        "\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "# Find all match elements\n",
        "match_elements = soup.find_all(\"div\", class_=\"matchCard\")\n",
        "\n",
        "# Extract data from each match element\n",
        "for match_element in match_elements:\n",
        "    # Teams\n",
        "    teams = match_element.find_all(\"div\", class_=\"teamName\")\n",
        "    team1 = teams[0].text.strip()\n",
        "    team2 = teams[1].text.strip()\n",
        "\n",
        "    # Date and Time\n",
        "    date_time = match_element.find(\"div\", class_=\"date\").text.strip()\n",
        "\n",
        "    # Stadium (if available)\n",
        "    stadium = match_element.find(\"div\", class_=\"stadium\").text.strip() if match_element.find(\"div\", class_=\"stadium\") else \"N/A\"\n",
        "\n",
        "    # Week (round)\n",
        "    week = match_element.find(\"div\", class_=\"week\").text.strip()\n",
        "\n",
        "    # Print the extracted data\n",
        "    print(f\"Teams: {team1} vs {team2}\")\n",
        "    print(f\"Date and Time: {date_time}\")\n",
        "    print(f\"Stadium: {stadium}\")\n",
        "    print(f\"Week: {week}\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-PR_HEHJwG0",
        "outputId": "002708ec-1459-49b3-82d0-043157e8f223"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_document(file_path):\n",
        "  if file_path.endswith(' .pdf '):\n",
        "    text = extract_text_from_pdf(file_path)\n",
        "    file_type = \"PDF\"\n",
        "  elif file_path.endswith(' .docx '):\n",
        "    text = extract_text_from_docx(file_path)\n",
        "    file_type = \"Word\"\n",
        "  elif file_path.endswith(' .pptx '):\n",
        "    text = extract_text_from_ppt(file_path)\n",
        "    file_type = \"PowerPoint\"\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported File Type\")\n",
        "  metdata = {\"author\": \"Unkown\", \"date\": \"2023-10-01\", \"source\": file_path}\n",
        "  return normalize_to_json(file_type, text, metadata)\n",
        "  procressed_data = preprocess_document('sample-1.pdf')\n",
        "  print(procressed_data)"
      ],
      "metadata": {
        "id": "Hle11L3VKMYe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from spire.pdf import PdfDocument, PdfTextExtractor, PdfTextExtractOptions\n",
        "import os\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    # Get the absolute path of the file\n",
        "    file_path = os.path.abspath(file_path)\n",
        "\n",
        "    doc = PdfDocument()\n",
        "    doc.LoadFromFile(\"sample.pdf\")\n",
        "    text = \"\"\n",
        "\n",
        "    for i in range(doc.Pages.Count):\n",
        "        page = doc.Pages.get_Item(i)\n",
        "        text += PdfTextExtractor(page).ExtractText(PdfTextExtractOptions())\n",
        "    doc.Close()\n",
        "    return text\n",
        "\n",
        "def normalize_to_json(file_type, content, metadata):\n",
        "    return {\"file_type\": file_type, \"content\": content, \"metadata\": metadata}\n",
        "\n",
        "# Get the absolute path of the PDF file\n",
        "pdf_file_path = os.path.abspath(\"sample-1.pdf\")\n",
        "\n",
        "pdf_text = extract_text_from_pdf(pdf_file_path)\n",
        "pdf_metadata = {\"author\": \"Unknown\", \"date\": \"2023-10-01\", \"source\": pdf_file_path}\n",
        "pdf_json = normalize_to_json(\"PDF\", pdf_text, pdf_metadata)\n",
        "print(json.dumps(pdf_json, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CebOW6D8KQLQ",
        "outputId": "0deb0896-b30a-4672-8faf-749c8705e295"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"file_type\": \"PDF\",\n",
            "    \"content\": \"Evaluation Warning : The document was created with Spire.PDF for Python.              Sample PDF\\n              This is a simple PDF \\ufb01le. Fun fun fun.\\n\\r\\n              Lorem ipsum dolor sit amet,  consectetuer adipiscing elit. Phasellus facilisis odio sed mi. \\n              Curabitur suscipit. Nullam vel nisi. Etiam semper ipsum ut lectus. Proin aliquam, erat eget \\n              pharetra  commodo,  eros  mi  condimentum  quam,  sed  commodo  justo  quam  ut  velit. \\n              Integer  a  erat.  Cras  laoreet  ligula  cursus  enim.  Aenean  scelerisque  velit  et  tellus. \\n              Vestibulum dictum aliquet sem.  Nulla facilisi.  Vestibulum accumsan  ante  vitae  elit.  Nulla \\n              erat  dolor,  blandit  in,  rutrum  quis,  semper  pulvinar,  enim.  Nullam varius  congue  risus. \\n              Vivamus  sollicitudin,  metus  ut  interdum  eleifend,  nisi  tellus  pellentesque  elit,  tristique \\n              accumsan  eros  quam et  risus.  Suspendisse  libero  odio,  mattis  sit  amet,  aliquet  eget, \\n              hendrerit vel, nulla. Sed vitae augue. Aliquam erat volutpat. Aliquam feugiat vulputate nisl. \\n              Suspendisse quis nulla pretium ante pretium mollis. Proin velit ligula, sagittis at, egestas a, \\n              pulvinar quis, nisl.\\n\\r\\n              Pellentesque  sit  amet  lectus.  Praesent  pulvinar,  nunc  quis  iaculis  sagittis,  justo  quam \\n              lobortis tortor, sed vestibulum dui metus venenatis est.  Nunc cursus ligula. Nulla facilisi. \\n              Phasellus ullamcorper consectetuer ante. Duis tincidunt, urna id condimentum luctus, nibh \\n              ante  vulputate  sapien,  id  sagittis  massa orci  ut  enim.  Pellentesque  vestibulum convallis \\n              sem. Nulla consequat quam ut nisl.  Nullam est.  Curabitur tincidunt dapibus lorem.  Proin \\n              velit  turpis,  scelerisque  sit amet,  iaculis nec,  rhoncus  ac,  ipsum.  Phasellus  lorem arcu, \\n              feugiat  eu,  gravida  eu,  consequat  molestie,  ipsum.  Nullam  vel  est  ut  ipsum  volutpat \\n              feugiat. Aenean pellentesque.\\n\\r\\n              In mauris.  Pellentesque dui  nisi, iaculis eu, rhoncus in, venenatis ac, ante.  Ut odio justo, \\n              scelerisque vel,  facilisis non, commodo a, pede. Cras nec massa sit amet tortor volutpat \\n              varius. Donec lacinia, neque a luctus aliquet, pede massa imperdiet ante, at varius lorem \\n              pede  sed sapien.  Fusce  erat nibh,  aliquet in, eleifend eget,  commodo eget,  erat. Fusce \\n              consectetuer.  Cras risus tortor,  porttitor nec, tristique  sed,  convallis semper,  eros. Fusce \\n              vulputate ipsum a mauris.  Phasellus mollis.  Curabitur sed urna. Aliquam nec sapien  non \\n              nibh  pulvinar  convallis.  Vivamus  facilisis  augue  quis  quam.  Proin  cursus aliquet  metus. \\n              Suspendisse lacinia.  Nulla at tellus ac turpis eleifend scelerisque. Maecenas a pede vitae \\n              enim commodo interdum. Donec odio. Sed sollicitudin dui vitae justo.\\n\\r\\n              Morbi elit nunc, facilisis a, mollis a, molestie at, lectus. Suspendisse eget mauris eu tellus \\n              molestie  cursus.  Duis  ut  magna at  justo  dignissim  condimentum.  Cum sociis  natoque \\n              penatibus et magnis dis parturient montes, nascetur ridiculus mus. Vivamus varius. Ut sit \\n              amet diam suscipit mauris ornare aliquam.  Sed  varius.  Duis arcu.  Etiam tristique massa \\n              eget dui. Phasellus congue. Aenean est erat, tincidunt eget, venenatis quis, commodo at, \\n              quam.\\n\\n\",\n",
            "    \"metadata\": {\n",
            "        \"author\": \"Unknown\",\n",
            "        \"date\": \"2023-10-01\",\n",
            "        \"source\": \"/content/sample-1.pdf\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\")\n",
        "\n",
        "def preprocess_document(file_path):\n",
        "  if file_path.endswith('.pdf'):\n",
        "    text = extract_text_from_pdf(file_path)\n",
        "    file_type = \"PDF\"\n",
        "  elif file_path.endswith('.docx'):\n",
        "    text = extract_text_from_docx(file_path)\n",
        "    file_type = \"Word\"\n",
        "  elif file_path.endswith('.pptx'):\n",
        "    text = extract_text_from_ppt(file_path)\n",
        "    file_type = \"PowerPoint\"\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported File Type\")\n",
        "  metadata = {\"author\": \"Unkown\", \"date\": \"2023-10-01\", \"source\": file_path}\n",
        "  return normalize_to_json(file_type, text, metadata)\n",
        "\n",
        "\n",
        "processed_data = preprocess_document('sample-1.pdf')\n",
        "print(processed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wnlCxZRKR5f",
        "outputId": "cb0b58bd-2ebf-41c7-dfab-59d05a790447"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'file_type': 'PDF', 'content': 'Evaluation Warning : The document was created with Spire.PDF for Python.              Sample PDF\\n              This is a simple PDF Ô¨Åle. Fun fun fun.\\n\\r\\n              Lorem ipsum dolor sit amet,  consectetuer adipiscing elit. Phasellus facilisis odio sed mi. \\n              Curabitur suscipit. Nullam vel nisi. Etiam semper ipsum ut lectus. Proin aliquam, erat eget \\n              pharetra  commodo,  eros  mi  condimentum  quam,  sed  commodo  justo  quam  ut  velit. \\n              Integer  a  erat.  Cras  laoreet  ligula  cursus  enim.  Aenean  scelerisque  velit  et  tellus. \\n              Vestibulum dictum aliquet sem.  Nulla facilisi.  Vestibulum accumsan  ante  vitae  elit.  Nulla \\n              erat  dolor,  blandit  in,  rutrum  quis,  semper  pulvinar,  enim.  Nullam varius  congue  risus. \\n              Vivamus  sollicitudin,  metus  ut  interdum  eleifend,  nisi  tellus  pellentesque  elit,  tristique \\n              accumsan  eros  quam et  risus.  Suspendisse  libero  odio,  mattis  sit  amet,  aliquet  eget, \\n              hendrerit vel, nulla. Sed vitae augue. Aliquam erat volutpat. Aliquam feugiat vulputate nisl. \\n              Suspendisse quis nulla pretium ante pretium mollis. Proin velit ligula, sagittis at, egestas a, \\n              pulvinar quis, nisl.\\n\\r\\n              Pellentesque  sit  amet  lectus.  Praesent  pulvinar,  nunc  quis  iaculis  sagittis,  justo  quam \\n              lobortis tortor, sed vestibulum dui metus venenatis est.  Nunc cursus ligula. Nulla facilisi. \\n              Phasellus ullamcorper consectetuer ante. Duis tincidunt, urna id condimentum luctus, nibh \\n              ante  vulputate  sapien,  id  sagittis  massa orci  ut  enim.  Pellentesque  vestibulum convallis \\n              sem. Nulla consequat quam ut nisl.  Nullam est.  Curabitur tincidunt dapibus lorem.  Proin \\n              velit  turpis,  scelerisque  sit amet,  iaculis nec,  rhoncus  ac,  ipsum.  Phasellus  lorem arcu, \\n              feugiat  eu,  gravida  eu,  consequat  molestie,  ipsum.  Nullam  vel  est  ut  ipsum  volutpat \\n              feugiat. Aenean pellentesque.\\n\\r\\n              In mauris.  Pellentesque dui  nisi, iaculis eu, rhoncus in, venenatis ac, ante.  Ut odio justo, \\n              scelerisque vel,  facilisis non, commodo a, pede. Cras nec massa sit amet tortor volutpat \\n              varius. Donec lacinia, neque a luctus aliquet, pede massa imperdiet ante, at varius lorem \\n              pede  sed sapien.  Fusce  erat nibh,  aliquet in, eleifend eget,  commodo eget,  erat. Fusce \\n              consectetuer.  Cras risus tortor,  porttitor nec, tristique  sed,  convallis semper,  eros. Fusce \\n              vulputate ipsum a mauris.  Phasellus mollis.  Curabitur sed urna. Aliquam nec sapien  non \\n              nibh  pulvinar  convallis.  Vivamus  facilisis  augue  quis  quam.  Proin  cursus aliquet  metus. \\n              Suspendisse lacinia.  Nulla at tellus ac turpis eleifend scelerisque. Maecenas a pede vitae \\n              enim commodo interdum. Donec odio. Sed sollicitudin dui vitae justo.\\n\\r\\n              Morbi elit nunc, facilisis a, mollis a, molestie at, lectus. Suspendisse eget mauris eu tellus \\n              molestie  cursus.  Duis  ut  magna at  justo  dignissim  condimentum.  Cum sociis  natoque \\n              penatibus et magnis dis parturient montes, nascetur ridiculus mus. Vivamus varius. Ut sit \\n              amet diam suscipit mauris ornare aliquam.  Sed  varius.  Duis arcu.  Etiam tristique massa \\n              eget dui. Phasellus congue. Aenean est erat, tincidunt eget, venenatis quis, commodo at, \\n              quam.\\n\\n', 'metadata': {'author': 'Unkown', 'date': '2023-10-01', 'source': 'sample-1.pdf'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the 'output' folder if it doesn't exist\n",
        "if not os.path.exists('output'):\n",
        "    os.makedirs('output')\n",
        "\n"
      ],
      "metadata": {
        "id": "0kR5UabCMp59"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# ... (Your existing code to extract and normalize data) ...\n",
        "\n",
        "# Assuming your normalization logic is in a function called 'preprocess_document'\n",
        "# and you want to process 'sample-1.pdf'\n",
        "normalized_data = preprocess_document('sample-1.pdf')\n",
        "\n",
        "# Save the normalized JSON data to a file in the 'output' folder\n",
        "with open(os.path.join('output', 'document_name.json'), 'w', encoding='utf-8') as f:\n",
        "    json.dump(normalized_data, f, indent=4)"
      ],
      "metadata": {
        "id": "rFqYxDW_M8LY"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}